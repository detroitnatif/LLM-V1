{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9506191f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['PATH'] += ':/opt/local/bin'\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0b0beed9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2024-02-18 17:07:53--  https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 1115394 (1.1M) [text/plain]\n",
      "Saving to: ‘input.txt’\n",
      "\n",
      "input.txt           100%[===================>]   1.06M  --.-KB/s    in 0.1s    \n",
      "\n",
      "2024-02-18 17:07:53 (10.9 MB/s) - ‘input.txt’ saved [1115394/1115394]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9866b25b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('input.txt', 'r', encoding='utf-8') as f:\n",
    "    text = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d980b060",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Characters in Dataset\n",
      "1115394\n"
     ]
    }
   ],
   "source": [
    "print(\"Characters in Dataset\")\n",
    "print(len(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "79a807b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Citizen:\n",
      "Before we proceed any further, hear me speak.\n",
      "\n",
      "All:\n",
      "Speak, speak.\n",
      "\n",
      "First Citizen:\n",
      "You are all resolved rather to die than to famish?\n",
      "\n",
      "All:\n",
      "Resolved. resolved.\n",
      "\n",
      "First Citizen:\n",
      "First, you know Caius Marcius is chief enemy to the people.\n",
      "\n",
      "All:\n",
      "We know't, we know't.\n",
      "\n",
      "First Citizen:\n",
      "Let us kill him, and we'll have corn at our own price.\n",
      "Is't a verdict?\n",
      "\n",
      "All:\n",
      "No more talking on't; let it be done: away, away!\n",
      "\n",
      "Second Citizen:\n",
      "One word, good citizens.\n",
      "\n",
      "First Citizen:\n",
      "We are accounted poor\n"
     ]
    }
   ],
   "source": [
    "print(text[:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "52d04c8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " !$&',-.3:;?ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz 65\n"
     ]
    }
   ],
   "source": [
    "chars = sorted(list(set(text)))\n",
    "vocab_size = len(chars)\n",
    "print(''.join(chars), len(chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "78c4b509",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "$\n",
      "[46, 47, 47, 47, 1, 58, 46, 43, 56, 43, 2]\n",
      "hiii there!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "s2i = {i:s for s, i in enumerate(chars)}\n",
    "i2s = {s:i for s, i in enumerate(chars)}\n",
    "encode = lambda s: [s2i[c] for c in s]\n",
    "decode = lambda l: ''.join([i2s[i] for i in l])\n",
    "\n",
    "a = encode(\"hiii there!\")\n",
    "print(a)\n",
    "print(decode(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "454424fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1115394]) torch.int64\n",
      "tensor([18, 47, 56, 57, 58])\n"
     ]
    }
   ],
   "source": [
    "data = torch.tensor(encode(text), dtype=torch.long)\n",
    "print(data.shape, data.dtype)\n",
    "print(data[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "aa025871",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = int(.9*len(data))\n",
    "train_data = data[:n]\n",
    "val_data = data[n:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "dc28c5ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([18])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "block_size = 8\n",
    "train_data[:block_size + 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "47590da5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "when input is tensor([18]), target is 47\n",
      "when input is tensor([18, 47]), target is 56\n",
      "when input is tensor([18, 47, 56]), target is 57\n",
      "when input is tensor([18, 47, 56, 57]), target is 58\n",
      "when input is tensor([18, 47, 56, 57, 58]), target is 1\n",
      "when input is tensor([18, 47, 56, 57, 58,  1]), target is 15\n",
      "when input is tensor([18, 47, 56, 57, 58,  1, 15]), target is 47\n",
      "when input is tensor([18, 47, 56, 57, 58,  1, 15, 47]), target is 58\n"
     ]
    }
   ],
   "source": [
    "x = train_data[:block_size]\n",
    "y = train_data[1:block_size+1]\n",
    "for t in range(block_size):  # WHEN YOU INDEX INTO THE FIRST ELEMENT\n",
    "    context = x[:t+1]        # ITS train_data[:1] not train_data[0]\n",
    "    target = y[t]\n",
    "    print(f'when input is {context}, target is {target}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "921dc371",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "b700c6ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ix\n",
      "tensor([29535, 38737, 81972, 56048])\n",
      "4 random numbers from len(data)\n",
      "\n",
      "x\n",
      "Index into 8 consectutive numbers\n",
      "tensor([[ 6,  1, 52, 53, 58,  1, 58, 47],\n",
      "        [ 6,  1, 54, 50, 39, 52, 58, 43],\n",
      "        [ 1, 58, 46, 47, 57,  1, 50, 47],\n",
      "        [ 0, 32, 46, 43, 56, 43,  1, 42]])\n",
      "y\n",
      "Index into 8 consectutive numbers offset by 1\n",
      "\n",
      "tensor([[ 1, 52, 53, 58,  1, 58, 47, 50],\n",
      "        [ 1, 54, 50, 39, 52, 58, 43, 58],\n",
      "        [58, 46, 47, 57,  1, 50, 47, 60],\n",
      "        [32, 46, 43, 56, 43,  1, 42, 53]])\n",
      "inputs\n",
      "torch.Size([4, 8])\n",
      "tensor([[ 6,  1, 52, 53, 58,  1, 58, 47],\n",
      "        [ 6,  1, 54, 50, 39, 52, 58, 43],\n",
      "        [ 1, 58, 46, 47, 57,  1, 50, 47],\n",
      "        [ 0, 32, 46, 43, 56, 43,  1, 42]])\n",
      "targets\n",
      "torch.Size([4, 8])\n",
      "tensor([[ 1, 52, 53, 58,  1, 58, 47, 50],\n",
      "        [ 1, 54, 50, 39, 52, 58, 43, 58],\n",
      "        [58, 46, 47, 57,  1, 50, 47, 60],\n",
      "        [32, 46, 43, 56, 43,  1, 42, 53]])\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(1337)\n",
    "batch_size = 4\n",
    "block_size = 8\n",
    "\n",
    "def get_batch(split):\n",
    "    data = train_data if split == \"test_data\" else val_data\n",
    "    ix = torch.randint(len(data) - block_size, (batch_size,)) # 0 to len of data - block size\n",
    "    x = torch.stack([data[i:i+block_size] for i in ix])\n",
    "    y = torch.stack([data[i+1:i+block_size+1] for i in ix])\n",
    "    \n",
    "    print('ix')\n",
    "    print(ix)\n",
    "    print(\"4 random numbers from len(data)\\n\")\n",
    "    \n",
    "    print('x')\n",
    "    print(\"Index into 8 consectutive numbers\")\n",
    "    print(x)\n",
    "    \n",
    "    print('y')\n",
    "    print(\"Index into 8 consectutive numbers offset by 1\\n\")\n",
    "    print(y)\n",
    "    \n",
    "    \n",
    "    return x, y\n",
    "\n",
    "xb, yb = get_batch('train')\n",
    "\n",
    "print(\"inputs\")\n",
    "print(xb.shape)\n",
    "print(xb)\n",
    "\n",
    "print(\"targets\")\n",
    "print(yb.shape)\n",
    "print(yb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "899fbf3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "torch.manual_seed(1337)\n",
    "g = torch.Generator()\n",
    "g.manual_seed(1337)\n",
    "\n",
    "class BigramLanguageModel(nn.Module):\n",
    "    \n",
    "    def __init__(self, vocab_size):\n",
    "        super().__init__()\n",
    "        self.token_embedding_table = nn.Embedding(vocab_size, vocab_size)\n",
    "        \n",
    "    def forward(self, idx, targets=None):\n",
    "        logits = self.token_embedding_table(idx) # CREATES B,T,C array which is Batch(4) x Time(8) x Channel(65)\n",
    "        B, T, C = logits.shape\n",
    "        \n",
    "        if targets is None:\n",
    "            loss = None\n",
    "        else:\n",
    "            B, T, C = logits.shape\n",
    "            logits = logits.view(B*T, C) # Flattening this to B*T, C\n",
    "            targets = targets.view(-1)\n",
    "            loss = F.cross_entropy(logits, targets)\n",
    "        \n",
    "        return logits, loss\n",
    "    \n",
    "    def generate(self, idx, max_new_tokens):\n",
    "        # Idx is (B,T) array of indices in the current context\n",
    "        for _ in range(max_new_tokens):\n",
    "            logits, loss = self(idx)\n",
    "#             print(logits.shape)\n",
    "            logits = logits[:, -1, :] # this slices the entire 1st and 3rd rows but only the last element of the 2nd\n",
    "#             print(logits.shape)\n",
    "            probs = F.softmax(logits, dim=-1)\n",
    "            idx_next = torch.multinomial(probs, num_samples=1, generator=g )\n",
    "            idx = torch.cat((idx, idx_next), dim=1)\n",
    "\n",
    "            \n",
    "        return idx\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "cc4167d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "$GodHZj3k-vvkj;YnlQBg\n",
      "vkx!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "m = BigramLanguageModel(vocab_size)\n",
    "logits, loss = m(xb, yb) # Taking 4 samples of 8 context and making 65 dimensions of embedding\n",
    "# print(loss)  # WITHOUT TRAINING THE LOSS SHOULD BE \"Negative Log Liklihood\" => log {-(1/65)}\n",
    "\n",
    "idx = torch.zeros((1, 1), dtype=torch.long)  # this is the newline character to kick off generation\n",
    "\n",
    "money = torch.tensor([[s2i['$']]])  # CREATE A 1x1 tensor with $ encoding (3) and start generating from that index\n",
    "n = m.generate(money, 25)[0].tolist()\n",
    "print(decode(n))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "b859ed9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a PyTorch Optimizer\n",
    "optimizer = torch.optim.AdamW(m.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "a82c2c8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.465340614318848\n",
      "\n",
      "JOHszcGI3zRqvLb&jNTCwHEN;A\n",
      "dMZ&B&gX ?f LGPA\n",
      "'PQK\n",
      "Y$GkraoXaWj;lkeC VlNIWJwbjnRQWZKZKQd.Q'M3vSEP;i\n",
      "C.W\n"
     ]
    }
   ],
   "source": [
    "batch = 32 \n",
    "for steps in range(100):\n",
    "    xb, yb = get_batch('train')\n",
    "    logits, loss = m(xb, yb)\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "print(loss.item())\n",
    "\n",
    "n = m.generate(idx, 100)[0].tolist()\n",
    "print(decode(n))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66140288",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eba1922b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
