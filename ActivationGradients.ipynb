{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1673520d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6e2d6379",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = open('names.txt', 'r').read().splitlines()\n",
    "\n",
    "chars = sorted(list(set(''.join(words))))\n",
    "i2s = {p+1:l for p, l in enumerate(chars)}\n",
    "i2s[0] = '.'\n",
    "\n",
    "s2i = {}\n",
    "\n",
    "for i, l in i2s.items():\n",
    "    s2i[l] = i\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "858211cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "block_size = 3\n",
    "\n",
    "def build_dataset(words):\n",
    "    X, Y = [], []\n",
    "    \n",
    "    for w in words:\n",
    "        context = [0] * block_size\n",
    "        for ch in w + '.':\n",
    "            ix = s2i[ch] \n",
    "            Y.append(ix)\n",
    "            X.append(context)\n",
    "            context = context[1:] + [ix]\n",
    "            \n",
    "    X = torch.tensor(X)\n",
    "    Y = torch.tensor(Y)\n",
    "    return X, Y\n",
    "\n",
    "import random\n",
    "random.seed(42)\n",
    "random.shuffle(words)\n",
    "\n",
    "n1 = int(.8*len(words))\n",
    "n2 = int(.9*len(words))\n",
    "\n",
    "Xtr, Ytr = build_dataset(words[:n1]) # train_words\n",
    "Xdev, Ydev = build_dataset(words[n1:n2]) # dev_words\n",
    "Xte, Yte = build_dataset(words[n2:]) # test_words\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c4fb92f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11897\n"
     ]
    }
   ],
   "source": [
    "g2 = torch.Generator().manual_seed(214748364)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "neurons = 200\n",
    "dimensions = 10 # dimensionality of embedding vector \n",
    "vocab_size = 27 # amount of characters (or words)\n",
    "C = torch.randn((vocab_size, dimensions), generator=g2) # 27 x n_embeddings this is a 2d vector of all the next possible characters\n",
    "W1 = torch.randn((block_size * dimensions, neurons), generator=g2) * (5/3) / ((block_size * dimensions) ** .5) # weights (block_size(3) x n_embeddings (10))  x N_neurons multplied by the kaiming_normal to keep gausian\n",
    "b1 = torch.randn(neurons, generator=g2)\n",
    "W2 = torch.randn((neurons,vocab_size), generator=g2) * .01 # creating second hidden layer which will take in the 100 transformed matrix and connect it to 27 output neurons\n",
    "b2 = torch.randn(vocab_size , generator = g2) * 0 # bias \n",
    "\n",
    "\n",
    "\n",
    "# BATCH_NORM PARAMS\n",
    "bngain = torch.ones((1, neurons))    # AVG GAIN TO MULT\n",
    "bnbias = torch.zeros((1, neurons))   # AVG BIAS TO ADD\n",
    "bnmean_running = torch.zeros((1, neurons))  \n",
    "bnstd_running = torch.ones((1, neurons))\n",
    "\n",
    "\n",
    "params = [C, W1, W2, b1, b2]\n",
    "num_params = sum(p.nelement() for p in params)\n",
    "print(num_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "80fa03c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = 200\n",
    "neur = 200\n",
    "dims = 10\n",
    "\n",
    "x = torch.randn(samples, dims) # 1000 ten-dimensional samples\n",
    "w = torch.randn(dims, neur) # 200 neurons that take 10 dimension\n",
    "y = (x @ w ) * dims ** .5 # this preserves the std of x when transforming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c3a8aaaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.5557, grad_fn=<NllLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "iters = 100\n",
    "lri = []\n",
    "lossi = []\n",
    "\n",
    "for p in params:\n",
    "    p.requires_grad = True\n",
    "\n",
    "for i in range(iters):\n",
    "    # Mini Sample\n",
    "    ix = torch.randint(0, Xtr.shape[0], (32,)) # this sample from 0 to size of X, batch size 32\n",
    "    \n",
    "    emb = C[Xtr[ix]]         # embed chars into vectors \n",
    "    embcat = emb.view(emb.shape[0], -1) # concat the vectors\n",
    "        \n",
    "    # CONVULTION (WEIGHT) LAYER\n",
    "    hpreact = embcat @ W1 + b1\n",
    "    \n",
    "    # BATCH NORM LAYER\n",
    "    bnmeani = hpreact.mean(0, keepdim=True)\n",
    "    bnstdi = hpreact.std(0, keepdim=True)\n",
    "    hpreact = (bngain * ((hpreact - bnmeani) / bnstdi)) + bnbias     \n",
    "    with torch.no_grad():\n",
    "        bnmean_running = .999 * bnmean_running + .001 * bnmeani\n",
    "        bnstd_running = .999 * bnstd_running + .001 * bnstdi\n",
    "\n",
    "    \n",
    "    # NON LINEARALITY LAYER\n",
    "    h = torch.tanh(hpreact)          \n",
    "    logits = h @ W2 + b2 # logits which are outputs\n",
    "    loss = F.cross_entropy(logits, Ytr[ix])\n",
    "    \n",
    "    \n",
    "    # counts = logits.exp()  OLD WAY TO CALCULATE LOSS ==> F.cross_entropy is better\n",
    "    # prob = counts / counts.sum(1, keepdim=True)\n",
    "    # loss = -prob[torch.arange(32), Y].log().mean() # this plucks the spot of probabilities following each Y\n",
    "    # print(loss)\n",
    "    # prob[0].sum()  == 1 #(normalized)\n",
    "    \n",
    "\n",
    "    # backward pass\n",
    "    for p in params:\n",
    "        p.grad = None\n",
    "\n",
    "    # BACK PROPOGATE\n",
    "    loss.backward()\n",
    "    \n",
    "    \n",
    "    lr = .1 # using minimum found on the graph\n",
    "    for p in params:\n",
    "        p.data += -lr * p.grad\n",
    "        \n",
    "    # track stats\n",
    "    lossi.append(loss.item())\n",
    "    final = loss\n",
    "\n",
    "x_plot = torch.arange(iters)\n",
    "# plt.plot(x_plot, lossi)\n",
    "print(final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fe6b5b7b",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "__enter__",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[0;32mIn [20]\u001b[0m, in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# m = hpreact.mean(0, keepdim=True)\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# s = hpreact.std(0, keepdim=True)\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad:\n\u001b[1;32m      5\u001b[0m     emb \u001b[38;5;241m=\u001b[39m C[Xtr]\n\u001b[1;32m      6\u001b[0m     embcat \u001b[38;5;241m=\u001b[39m emb\u001b[38;5;241m.\u001b[39mview(emb\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: __enter__"
     ]
    }
   ],
   "source": [
    "# m = hpreact.mean(0, keepdim=True)\n",
    "# s = hpreact.std(0, keepdim=True)\n",
    "\n",
    "with torch.no_grad:\n",
    "    emb = C[Xtr]\n",
    "    embcat = emb.view(emb.shape[0], -1)\n",
    "    hpreact = embcat @ W1 + b1\n",
    "    bnmean = hpreact.mean(0, keepdim=True)\n",
    "    bnstd = hpreact.std(0, keepdim=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "41a17f34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dol.\n",
      "myem.\n",
      "ohhhgem.\n",
      "meroreiss.\n",
      "kvyshaayyf\n",
      "werdiah.\n",
      "tptrieofql\n",
      "dmhnemihjy\n",
      "dubilaohe.\n",
      "meu.\n",
      "slochardeh\n",
      "hfkimilpjr\n",
      "simee.\n",
      "uardeohadc\n",
      "hartyfzarr\n",
      "gaz.\n",
      "qqmoinlies\n",
      "khonayxslv\n",
      "sa.\n",
      "lym.\n"
     ]
    }
   ],
   "source": [
    "# sample from the model\n",
    "g = torch.Generator().manual_seed(214748364 + 2)\n",
    "\n",
    "for _ in range(20):\n",
    "    \n",
    "    out = []\n",
    "    context = [0] * block_size # initialize with all ...\n",
    "    count = 0\n",
    "    while True:\n",
    "        emb = C[torch.tensor([context])] # (1,block_size,d)\n",
    "        embcat = emb.view(emb.shape[0], -1)\n",
    "        hpreact = embcat @ W1 + b1\n",
    "        h = torch.tanh(hpreact) \n",
    "        logits = h @ W2 + b2\n",
    "        probs = F.softmax(logits, dim=1)\n",
    "        ix = torch.multinomial(probs, num_samples=1, generator=g).item()\n",
    "        context = context[1:] + [ix]\n",
    "        out.append(ix)\n",
    "        count +=1 \n",
    "        if ix == 0:\n",
    "            break\n",
    "        if count == 10:\n",
    "            break\n",
    "    \n",
    "    print(''.join(i2s[i] for i in out))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3e601236",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f94e208e280>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 2000x1000 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "plt.imshow(h.abs() > .99, cmap='gray', interpolation='nearest')\n",
    "# this must be a small number or plot wont work\n",
    "# this graph shows black if the neuron is being trained and white if it was too close to -1, 1 and tanh function removed it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5f16379",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(h.view(-1).tolist(), 50);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e3335ee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
